# My project 

As part 1, my project is to propose a way of enconding soldier's letters from the First Wolrd War. 

At first, I wanted to encoding letters from different country and languages. The project was to create link between first world war slangs, unique to it, in order to cross the linguistic aspect. It seems to be a little bit ambitious : it asked linguistic and technical skills that I do not have at my disposition. 

So, I choose to focus on french soldier's, called "poilus", letters which are note transcribed in XML.

My project aimed to encoding those sources, based on TEI_all schema, with a focus on slang trench and expressions proper to that war. On a second hand, I aimed to focus on identification of person, places and events related to those letters. 

With those two objective, I want to propose a way of making a digital edition of those letters. 

<br>

# My materials 

I selected three letters from three different "poilus". 

Two letters are coming from the municipal archives of Reims. It is two different "poilus" who wrote them on the same year, 1 month apart between november and december 1914. They are the same as part 1 assignment. 

The third letter is new. The previous document I considered was not written by a soldier, so I replaced it. The new letter comes from an unidentified poilu and was taken from a PDF published by the Prefecture of the Manche département. It was written in August 1914 in Châlons-en-Champagne. I extracted only the first letter from the PDF, which presents several. *(see source_extract.xml)*

I selected these letters because of there physical and logical structure differences. 

<br>

# My approach 

As described a little bit in the "My project" part, my approach is to propose a digital edition as well as a way of encoding those text. 

So I tried to select the elements that seems to be pertient to propose a digital edition focused on make those sources exploitable more easily for lexical and linguistic studies as well as genalogical research. 

<br>

# AI statement 

No AI has been used for this part2.
